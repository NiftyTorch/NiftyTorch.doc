{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NiftyTorch\n",
    "NiftyTorch is a python API for deploying deep neural networks for Neuroimaging research.\n",
    "\n",
    "The goal is to provide a one stop API using which the users can perform classification tasks, Segmentation tasks and Image Generation tasks.\n",
    "The intended audience are the members of neuroimaging who would like to explore deep learning but have no background in coding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the environment \n",
    "Open command shell (e.g. Terminal in MacOS) and create a virtual environment using below commands. This will allow the installation of NiftyTorch dependencies indepednent of your local installs. This is inparticular useful if NiftyTorch is being used on an external server. This document that [conda](https://docs.conda.io/projects/conda/en/latest/user-guide/install/) is already installed on your server or local machine. \n",
    "\n",
    "- `%%bash` indicates that the code inside the cell should be run on command shell. If you use Jupyter notebook to run your code, the command will automatically run on command shell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you are instally NiftyTorch on your local machine, you can skip this step\n",
    "%%bash\n",
    "# create a virutal environment using python 3.6 or above\n",
    "conda create -n nt python=3.6 \n",
    "\n",
    "# you can assign a specific directory for your virutal environment \n",
    "conda create --prefix=/{PAHT TO ENV DIRECTORY}/nt python=3.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activate the virtual environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "conda activate nt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install dependencies\n",
    "install below softwares and libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# install NiftyTorch \n",
    "pip install niftytorch==0.1.1 --extra-index-url=https://pypi.org/simple/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If NiftyTorch generated error about pytorch version, use below command to change your dependencies versions. Also you can use `--no-deps` option to `pip install` to ignore dependencies and install `niftytorch` anyway, which is not recommended. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here are some dependencies and their version that have been tested for compatibility with NiftyTorch\n",
    "# pip install torchvision==0.5.0\n",
    "# pip install torch==1.4.0\n",
    "# pip install nipy==0.4.2\n",
    "# pip install numpy==1.16.4\n",
    "# pip install pandas==1.0.3\n",
    "# pip install matplotlib==3.2.1\n",
    "# pip install Optuna==1.3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run an example deep learning classifier on your data using NiftyTorch\n",
    "We assumed the your data is structured as follow. SubjectIDs should be randomly assigned to training, validation and test sets. \n",
    "\n",
    "Here `t1w.nii.gz` and `t2w.nii.gz` are included as examples. Users can include any modality (or derived maps) of interest. Data should be in nifti format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "StudyName\n",
    "    └───train\n",
    "    │   └───subjectID\n",
    "    │   │       t1w.nii.gz\n",
    "    │   │       t2w.nii.gz\n",
    "    │   └───subjectID\n",
    "    │           t1w.nii.gz\n",
    "    │           t2w.nii.gz               \n",
    "    │       ...\n",
    "    └───val\n",
    "    │   └───subjectID\n",
    "    │   │       t1w.nii.gz\n",
    "    │   │       t2w.nii.gz\n",
    "    │   └───subjectID\n",
    "    │           t1w.nii.gz\n",
    "    │           t2w.nii.gz               \n",
    "    │       ...\n",
    "    └───test\n",
    "        └───subjectID\n",
    "        │       t1w.nii.gz\n",
    "        │       t2w.nii.gz\n",
    "        └───subjectID\n",
    "                t1w.nii.gz\n",
    "                t2w.nii.gz               \n",
    "            ...\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you are ready to use NiftyTorch. Run below code in python environment (or in Jupyter notebook) to train a deep learning classifier on your data.  \n",
    "Here we show an example using the [XNOR-Net](https://arxiv.org/abs/1603.05279) or [Alex-Net](https://en.wikipedia.org/wiki/AlexNet#cite_note-quartz-1).  \n",
    "\n",
    "\n",
    "The classifier is training a network to predict Alzheimer's patient from cognitively healhty individuals using `t1w` and `t2w` MRI. The labels should be stored in a separate CSV file (here called `labels.csv`), and should contain a column with the sampe subject IDS (here the column name is `Subject`) and a column with disease status (e.g. 0 for healthy controls and 1 for AD patients - here the column name is `diease`). \n",
    "\n",
    "`SubjecID` can be any subject ID of your choice. for example: `sub-01`, `sub-02`, ... . We plan to add BIDS compatibility. \n",
    "\n",
    "Here is an example of the `labels.csv` data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>SUBJ01</td>\n",
       "      <td>70</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>SUBJ02</td>\n",
       "      <td>65</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>SUBJ03</td>\n",
       "      <td>69</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>SUBJ04</td>\n",
       "      <td>71</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>SUBJ05</td>\n",
       "      <td>68</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Subject  age gender  diagnosis\n",
       "0  SUBJ01   70      M          1\n",
       "1  SUBJ02   65      M          1\n",
       "2  SUBJ03   69      F          0\n",
       "3  SUBJ04   71      F          1\n",
       "4  SUBJ05   68      M          0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "study_folder = \"/example/farshid/img/data/StudyName\"\n",
    "labels = pd.read_csv(study_folder+\"/labels.csv\")\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XNOR-net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an example of training a XNOR-Net for disease classification. Hyper-parameters should be optimized for your application and dataset. Other parameters, such as number of epochs, should be modified accordingly as well. We included some of the features of NiftyTorch in below example, such as:\n",
    "* Incorporate demographic information through attention gate: `demographic = ['age','gender']`\n",
    "* Assign specific data for training: `file_type = ('t1w.nii.gz','t2w.nii.gz')`. You can use single or multiple data inputs as training channels. Note that if this is not assigned, all the images in subject folder will be used. \n",
    "* Data parallelization: `device_ids = ['cuda:2','cuda:5']`. Data will be allocated to multiple GPUs. Note that this can slow down the training process due to the additional background integration. This option is only required in rare cases that each sample size is large relative to the GPU RAM.\n",
    "* `cuda = 'cuda:5'` assign GPU number 5 for this task. Use `nvidia-smi` to check the status of your GPU device. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import torch\n",
    "from niftytorch.Models.XNOR_NET import train_xnornet\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "\n",
    "# create data-to-tensor transform\n",
    "data_transforms = transforms.Compose([transforms.ToTensor()])\n",
    "        \n",
    "# add path to your data folder\n",
    "data_folder = \"/example/farshid/img/data/StudyName\"\n",
    "\n",
    "# add path to labels\n",
    "data_csv = \"/example/farshid/img/data/StudyName/labels.csv\"\n",
    "\n",
    "# train classifier using XNOR Net\n",
    "train = train_xnornet()\n",
    "\n",
    "# set training parameters\n",
    "# training will be done using:\n",
    "# Entries in the 'Subject' column\n",
    "# Labels: class_label = 'diagnosis'\n",
    "train.set_params(\n",
    "    num_classes = 2,\n",
    "    in_channels = 2,\n",
    "    data_folder = data_folder,\n",
    "    data_csv = data_csv,\n",
    "    channels = [1,2,4,2,1],\n",
    "    kernel_size = [3,5,5,3,1],\n",
    "    strides = [1,2,2,2,1],\n",
    "    padding = [1,1,1,1,1],\n",
    "    groups = [1,1,1,1,1],\n",
    "    data_transforms = data_transforms,\n",
    "    l2 = 3e-4,\n",
    "    learning_rate = 1e-3,\n",
    "    step_size = 10,\n",
    "    gamma = 0.1,\n",
    "    cuda = 'cuda:5',\n",
    "    device_ids = ['cuda:2','cuda:5'],\n",
    "    batch_size = 128,\n",
    "    image_scale = 128,\n",
    "    num_epochs = 20,\n",
    "    optimizer = torch.optim.Adam,\n",
    "    filename_label = 'Subject',\n",
    "    class_label = 'diagnosis',\n",
    "    file_type = ('t1w.nii.gz','t2w.nii.gz'),\n",
    "    demographic = ['age','gender']\n",
    "    )\n",
    "train.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important note before applying prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Users should carefully choose the loss function and the optimizer depending on the data and application. For example, imbalanced datasets, which is common in medical imaging, require a loss function that incorporates class imbalance (such as `Focal Loss` or `Weighted Cross Entropy` - See Loss Documentation for more details).  \n",
    "\n",
    "> Note that the performance of any network dependents on the optimization of the hyperparamters. User should optimize network for optimum performance. **NiftyTorch** has a module that helps with the hyperparameter optimization, which is detailed in **Demo 3: Automated Hyperparamter Optimization**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction (applying the classifier)\n",
    "The next step would be to perform the classification on the test data to see how well the model has learned the weights after the completion of the training process.\n",
    "\n",
    "Note that the testing parameters is same as that of the training parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "# define batch_size for testing\n",
    "batch_size = 32\n",
    "\n",
    "# define the scale of image while tesing\n",
    "image_scale = 128\n",
    "\n",
    "# define the loss function for evaluation during testing\n",
    "test_criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# device on the network would be trained\n",
    "device = torch.device('cuda:5')\n",
    "\n",
    "# called the predict function which has the parameters internally stored\n",
    "train.predict(data_folder = data_folder,\n",
    "              data_csv = data_csv,\n",
    "              data_transforms = data_transforms,\n",
    "              filename_label = 'Subject',\n",
    "              class_label = 'disease',\n",
    "              image_scale = image_scale,\n",
    "              batch_size = batch_size,\n",
    "              num_workers = 4,\n",
    "              test_criterion = test_criterion, \n",
    "              file_type = ('t1w.nii.gz','t2w.nii.gz'),\n",
    "              demographic = ['age','gender'],\n",
    "              device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of this stage will be the predicted classes and the overal accuracy over the testing samples. The prediction will be reported in the form of `SubjectID tensor (predicted class, device=GPU used)`\n",
    "For example, below are prediction results of 7 subjects from testing: \n",
    "```\n",
    "sub-09935 tensor(0, device='cuda:5')\n",
    "sub-04622 tensor(1, device='cuda:5')\n",
    "sub-05725 tensor(1, device='cuda:5')\n",
    "sub-00008 tensor(1, device='cuda:5')\n",
    "sub-03721 tensor(0, device='cuda:5')\n",
    "sub-01717 tensor(0, device='cuda:5')\n",
    "sub-01818 tensor(1, device='cuda:5')\n",
    "test Classification Loss: 0.5435 Acc: 0.7436\n",
    "Testing complete in 0m 38s\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congradulations, you have a Deep Learning classifier now. To save the the weights of your trained network you can use `get_model` function in the train object."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
