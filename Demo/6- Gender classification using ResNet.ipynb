{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gender classification using ResNet\n",
    "As a challenging task, we use T1w data of cognitively healthy individuals across lifespan and predict their gender. We used human connectome project [data](https://www.humanconnectome.org) for this example.  \n",
    "\n",
    "We used NiftyTorch 3D implementation of [ResNet](https://arxiv.org/abs/1512.03385), and achieved >79% accuracy on validation data. Note that this despite the fact that we did not fully optimze the hyperparameters and used only 10 epocs for the demo purpose. \n",
    "\n",
    "This demo is a typical example that users can use for different classification applications. For the privacy reasons, we removed path to data from the demo widgets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.manual_seed(0)\n",
    "from niftytorch.Models.ResNet import train_resnet\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "from niftytorch.Layers.Convolutional_Layers import Bottleneck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = transforms.Compose([transforms.ToTensor()]) \n",
    "data_folder = \"path_to_hcp_data/\"\n",
    "data_csv = \"path_to_hcp_data/labels.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Usage:\n",
      "from Models.3D_ResNet import train_resnet\n",
      "trainer = train_resnet()\n",
      "data_folder = '../data'\n",
      "data_csv = '../data/distribution.csv'\n",
      "trainer.set_params(num_classes = 2,in_channels = 1,data_folder,data_csv,learning_rate = 1e-3,step_size = 5,gamma = 0.01,cuda = 'cuda:0')\n",
      "trainer.train()\n",
      "parameters:\n",
      "num_classes: the number of classes in dataset\n",
      "in_channels: the number of channels in the input image\n",
      "data_folder: the directory where the data is present\n",
      "data_csv: the csv where the data and class map is given\n",
      "learning_rate: the learning rate for gradient update\n",
      "step_size: for reducing the learning rate\n",
      "gamma: reduction ratio in the learning_rate\n",
      "cuda: cuda gpu number\n",
      "batch_size: the number of examples to be used for gradient update\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train = train_resnet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [1,2,1,2]\n",
    "stride = [1,1,1,1,1]\n",
    "channels = [32,64,64,32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Usage:\n",
      "from Models.3D_ResNet import train_resnet\n",
      "trainer = train_resnet()\n",
      "data_folder = '../data'\n",
      "data_csv = '../data/distribution.csv'\n",
      "trainer.set_params(num_classes = 2,in_channels = 1,data_folder,data_csv,learning_rate = 1e-3,step_size = 5,gamma = 0.01,cuda = 'cuda:0')\n",
      "trainer.train()\n",
      "parameters:\n",
      "num_classes: the number of classes in dataset\n",
      "in_channels: the number of channels in the input image\n",
      "data_folder: the directory where the data is present\n",
      "data_csv: the csv where the data and class map is given\n",
      "learning_rate: the learning rate for gradient update\n",
      "step_size: for reducing the learning rate\n",
      "gamma: reduction ratio in the learning_rate\n",
      "cuda: cuda gpu number\n",
      "batch_size: the number of examples to be used for gradient update\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train = train_resnet()\n",
    "train.set_params(\n",
    "    num_classes = 2,\n",
    "    in_channels = 1,\n",
    "    data_folder = data_folder,\n",
    "    data_csv = data_csv,\n",
    "    block = Bottleneck,\n",
    "    data_transforms = data_transforms,\n",
    "    filename_label = 'Subject',\n",
    "    class_label = 'gender',\n",
    "    layers = layers,\n",
    "    stride = stride,\n",
    "    channels = channels,\n",
    "    learning_rate = 3e-3,\n",
    "    step_size = 7,\n",
    "    gamma = 0.1,\n",
    "    cuda = 'cuda:4',\n",
    "    batch_size = 32,\n",
    "    image_scale = 80,\n",
    "    file_type = ('t1w.nii.gz'),\n",
    "    num_epochs = 10\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{-1: 0, 1: 1}\n",
      "{-1: 0, 1: 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "train Classification Loss: 0.6343 Acc: 0.6758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 1/10 [19:14<2:53:08, 1154.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Classification Loss: 0.6126 Acc: 0.7516\n",
      "\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Classification Loss: 0.6237 Acc: 0.7156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 2/10 [38:28<2:33:53, 1154.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Classification Loss: 0.6128 Acc: 0.7660\n",
      "\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Classification Loss: 0.6241 Acc: 0.7224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 3/10 [57:54<2:15:04, 1157.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Classification Loss: 0.6128 Acc: 0.7681\n",
      "\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Classification Loss: 0.6245 Acc: 0.7213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 4/10 [1:16:11<1:53:58, 1139.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Classification Loss: 0.6132 Acc: 0.7826\n",
      "\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Classification Loss: 0.6238 Acc: 0.7139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 5/10 [1:35:17<1:35:07, 1141.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Classification Loss: 0.6130 Acc: 0.7743\n",
      "\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Classification Loss: 0.6239 Acc: 0.7093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 6/10 [1:53:46<1:15:26, 1131.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Classification Loss: 0.6133 Acc: 0.7888\n",
      "\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Classification Loss: 0.6228 Acc: 0.7235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 7/10 [2:13:24<57:16, 1145.54s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Classification Loss: 0.6129 Acc: 0.7764\n",
      "\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Classification Loss: 0.6233 Acc: 0.7230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 8/10 [2:31:57<37:51, 1135.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Classification Loss: 0.6129 Acc: 0.7785\n",
      "\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Classification Loss: 0.6237 Acc: 0.7218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 9/10 [2:51:23<19:04, 1144.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Classification Loss: 0.6134 Acc: 0.7950\n",
      "\n",
      "Epoch 9/9\n",
      "----------\n",
      "train Classification Loss: 0.6240 Acc: 0.7196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [3:09:43<00:00, 1138.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Classification Loss: 0.6132 Acc: 0.7930\n",
      "\n",
      "Training complete in 189m 44s\n",
      "Best val Acc: 0.795031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.7950, device='cuda:2', dtype=torch.float64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "Below code can then be applied on new data stored in `study_folder/sub-ID/` using following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "train.predict(data_folder,\n",
    "              data_csv,\n",
    "              data_transforms,\n",
    "              'Subject',\n",
    "              'gender',\n",
    "              80,\n",
    "              1,\n",
    "              4,\n",
    "              nn.CrossEntropyLoss(),\n",
    "              'cuda:2',\n",
    "              ('t1w.nii.gz'))"
   ]
  },
  {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HCP996782 0\n",
      "HCP957974 1\n",
      "HCP972566 1\n",
      "HCP991267 0\n",
      "HCP958976 1\n",
      "HCP978578 1\n",
      "HCP992673 0\n",
      "HCP955465 1\n",
      "HCP990366 1\n",
      "HCP979984 1\n",
      "HCP987983 1\n",
      "HCP994273 0\n",
      "HCP959574 0\n",
      "HCP983773 0\n",
      "HCP965771 0\n",
      "HCP992774 0\n",
      "HCP966975 0\n",
      "HCP965367 0\n",
      "HCP993675 0\n",
      "HCP984472 1\n",
      "test Classification Loss: 0.6732 Acc: 0.6500\n",
      "Testing complete in 0m 6s"
     ]
   },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
