{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation example\n",
    "Here we provide a simple demo to perform U-Net segmentation on FLAIR, t1w data to segment brain tumors. \n",
    "\n",
    "For this purpose, we used publicaly available MRI data, thanks to [Decathlon 10 Challenge](https://decathlon-10.grand-challenge.org)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File structure\n",
    "For segmentation purpose, NiftyTorch requires below folder/file organization:\n",
    "```\n",
    "StudyName\n",
    "    └───train\n",
    "    │   └───subjectID\n",
    "    │          flair.nii.gz\n",
    "    │          t1w.nii.gz\n",
    "    │          seg.nii.gz\n",
    "    │           ...\n",
    "    └───val\n",
    "    │   └───subjectID\n",
    "    │          flair.nii.gz\n",
    "    │          t1w.nii.gz\n",
    "    │          seg.nii.gz\n",
    "    │           ...\n",
    "    └───test\n",
    "        └───subjectID\n",
    "               flair.nii.gz\n",
    "               t1w.nii.gz\n",
    "                ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`flair.nii.gz`, `t1w.nii.gz` etc are the inputs of the U-Net segmentation and `seg.nii.gz` is the label mask. \n",
    "> Note that test folder does not have to contain `seg.nii.gz`. If the labels are provided, the prediction code will also output the loss and accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example data\n",
    "An axial mosaic view of the FLAIR data that contains the tumor is shown here:\n",
    "\n",
    "![flair_example](./files/flair_example_mosaic.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define paths "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from niftytorch.Models.Unet import *\n",
    "from niftytorch.Loader.Segmentation_DataLoader import ImageFolder\n",
    "\n",
    "data_dir = '/example/farshid/img/data/TumorSeg'\n",
    "train_path = data_dir+'/train/'\n",
    "val_path = data_dir+'/val/'\n",
    "test_path = data_dir+'/test/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UnetModel = train_unet() \n",
    "UnetModel.set_params(\n",
    "    train_data = train_path, \n",
    "    val_data = val_path, \n",
    "    test_data = test_path, \n",
    "    batch_size = 32, \n",
    "    in_channels = 1, \n",
    "    out_channels = 1 \n",
    "    num_epochs = 20, \n",
    "    learning_rate = 0.01)\n",
    "UnetModel.train() \n", 
    "\n",
    "print(\"TRAINING DONE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results of the training, including Dice loss error across epocs will be reported here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
    "The training code also saves the generated model in the file path corresponding to training data. This can be loaded as provided in the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'data_dir+'/train/UNet_generated_model
    "trained_model = torch.load(PATH) \n", 
    "UNetModel.predict(trained_model) \n",
    "\n",
    "print(\"PREDICTION DONE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage a new data called `pred_UNet.nii.gz` will be saved in the testing folder with the result of the segmentation. \n",
    "\n",
    "`pred_UNet.nii.gz` is a probability map of the tumor, which you can binarize to obtain a mask. \n",
    "\n",
    "Change the number of out channels, by providing out_channels = 4 for getting a multi channel output. \n",     
    "UNet model can be trained by loading data corresponding to multiple modality at the same time by setting the in_channels and filename parameter to 2 and ('flair.nii.gz', 't1w.nii.gz') respectively \n",
    "The corresponding code and output would be as below \n",
    ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UnetModel = train_unet() \n", 
    "UnetModel.set_params(\n",
    "    train_data = train_path, \n",
    "    val_data = val_path, \n",
    "    test_data = test_path, \n",
    "    batch_size = 32, \n",
    "    in_channels = 2, \n",
    "    out_channels = 4 \n",
    "    filename = ('flair.nii.gz', 't1w.nii.gz'), \n",
    "    learning_rate = 0.01)\n"
    ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [    
    "![multiclass_example]" 
    "Here we overlaid the `pred_UNet.nii.gz` on input `flair.nii.gz`:\n",
    "\n",
    "<!-- <video controls width=300 src=\"./files/segmentation.mov\" /> -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"./files/segmentation.mov\" controls  width=\"300\" >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Video\n",
    "Video(\"./files/segmentation.mov\",width=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The most basic Unet implementation can be summerized to 4 lines of code:\n",
    "from niftytorch.Models.Unet import *\n",
    "data_dir = '/example/farshid/img/data/TumorSeg'\n",
    "UnetModel = train_unet.set_params(train_data = data_dir+'/train/', val_data = data_dir+'/val/',test_data = data_dir+'/test/', batch_size = 25, in_channels = 1, out_channels = 1)\n",
    "generated_model = UNetModel.train() \n", 
    "UNetModel.predict(generated_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
